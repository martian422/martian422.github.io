<!DOCTYPE html>

<HTML>
<HEAD>
  <META content="IE=5.0000" http-equiv="X-UA-Compatible">
  <META name="description" content="Tianren Ma's home page"> 
  <META http-equiv="Content-Type" content="text/html; charset=gb2312">
  <LINK href="files/doc.css" 
    rel="stylesheet" type="text/css"> 
  <TITLE>Tianren Ma 马天任</TITLE> 
  <META name="GENERATOR" content="MSHTML 11.00.10570.1001">
</HEAD>


<BODY> 
  <DIV id="layout-content" style="margin-top: 25px;">
  <TABLE>
    <TBODY>
    <TR>
      <TD width="670">
        <DIV id="toptitle">
        <H1>Tianren Ma &nbsp;</H1></DIV>
        <H3>Ph.D. Candidate</H3>
        <BR>Learning and Machine Perception Lab (LAMP)
        <BR>School of Electronic, Electrical and Communication Engineering
        <BR>University of Chinese Academy of Sciences (UCAS)
        <BR>Beijing, China, 100083.
        <BR>
        <BR> Email:  
        <A href="mailto:matianren18@mails.ucas.ac.cn"> matianren18@mails.ucas.ac.cn</A>; 
        <BR> Github: 
        <A href="https://github.com/martian422">https://github.com/martian422</A>;
        <BR><BR></P>
      </TD>
      <TD>
        <IMG width="200" src="files/welt.jpg" border="0">
      </TD>
    </TR>
    <TR></TR></TBODY>
  </TABLE>
  <DIV id="layout-content" style="margin-top: 25px;">


  <H2>Biography</H2>
  
  <P> I am a Ph.D. candidate of <A href="http://lamp.ucas.ac.cn/">LAMP</A> at <A href="http://english.ucas.ac.cn/">UCAS</A>, 
    advised by <A href="https://scholar.google.com.hk/citations?user=tjEfgsEAAAAJ&hl=zh-CN&oi=ao">Prof. Qixiang Ye</A>.       
  </P>

  <p>I got my B.E. degree in University of Chinese Academy of Sciences in 2022.</p>

  <P> During my undergraduate studies, I participated in satellite projects and contributed to the development of remote sensing algorithms. 
    My previous works focus on empowering large models to carry out instance-level comprehension, 
    and I'm interested in advancing multimodal model's capability with flexible and finer-grained interactions through discrete representations. 
  </P>


  <H2>Publications</H2>
    <table class="pub_table">
    <!-- <tbody> -->

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/clawmachine-1.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Tianren Ma</u>, Lingxi Xie, Yunjie Tian, Boyu Yang, Qixiang Ye
          <br><b>ClawMachine: Learning to Fetch Visual Tokens for Referential Comprehension</b>
          <br>ICLR, 2025
          <br>
          [<a href="https://arxiv.org/pdf/2406.11327">Paper</a>]
          [<a href="https://github.com/martian422/ClawMachine">Code</a>]
          <br>
        </td>
      </tr>


      <tr>
        <td class="pub_td1"><img src="files/PaperFig/chatterbox.png" class="papericon"></td>
        <td 
          class="pub_td2">Yunjie Tian*, <u>Tianren Ma*</u>, Lingxi Xie, Qixiang Ye
          <br><b>ChatterBox: Multimodal Referring and Grounding with Chain-of-Questions</b>
          <br>AAAI, 2025
          <br>
          [<a href="https://arxiv.org/pdf/2401.13307">Paper</a>]
          [<a href="https://github.com/sunsmarterjie/ChatterBox">Code</a>]
          <br>
        </td>
      </tr>
  
      <tr>
        <td class="pub_td1"><img src="files/PaperFig/artemis.png" class="papericon"></td>
        <td 
          class="pub_td2">Jihao Qiu*, Yuan Zhang*, Xi Tang*, Lingxi Xie, <u>Tianren Ma</u>, Pengyu Yan, David Doermann, Qixiang Ye, Yunjie Tian
          <br><b>Artemis: Towards Referential Understanding in Complex Videos</b>
          <br>NeurIPS, 2024
          <br>
          [<a href="https://arxiv.org/abs/2406.00258">Paper</a>]
          [<a href="https://github.com/qiujihao19/Artemis">Code</a>]
          <br>
        </td>
      </tr>

    <!-- </tbody> -->
    </table>

  <P style="font-size: 90%;"><em>   * indicates equal contribution.</em></P>
    

</BODY>
</HTML>
